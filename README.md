# 프로젝트: 컴퓨터 비전 기반 고관절 움직임 분석 (Computer Vision-based Hip Motion Analysis)



## 📌 프로젝트 소개 (Introduction)



이 프로젝트는 컴퓨터 비전 기술을 활용하여 2D 영상 속 인체의 고관절 움직임을 정량적으로 분석합니다. 무용 동작과 같은 복합적인 움직임의 과학적 원리를 규명하고, 이를 통해 인체 역학에 대한 깊은 인사이트를 얻는 것을 목표로 합니다. 특히, 단순한 각도 측정을 넘어 여러 각도(굴곡, 외전, 외회전)가 복합적으로 발생하는 다면적인 움직임을 분석하는 데 중점을 두었습니다.



## 🚀 주요 기능 (Key Features)



* 실시간 포즈 추정 : 영상에서 MediaPipe 라이브러리를 사용해 인체 주요 랜드마크를 추출합니다.

* 고관절 각도 계산 : 랜드마크 데이터를 기반으로 굴곡/신전, 외전/내전, 외회전/내회전 등 고관절의 다양한 각도를 계산합니다.

* 영상-그래프 동기화 시각화 : 분석된 각도 데이터를 시간 흐름에 따라 그래프로 시각화하고, 이를 원본 영상과 동기화하여 동시에 재생합니다. 이를 통해 '어떤 동작을 할 때 각도가 어떻게 변하는지'를 직관적으로 파악할 수 있습니다.

* 샘플 데이터 제공 : 분석된 데이터는 CSV 파일로 저장되어 제공됩니다.



## 🛠️ 기술 스택 (Technologies Used)



* 언어 : Python

* 주요 라이브러리 : OpenCV, MediaPipe(Pose Estimation), NumPy, pandas, Matplotlib, SciPy



## 📁 파일 구조 (File Structure)



* 1 extract\_data.py : 영상에서 랜드마크를 추출하고 CSV 파일로 저장하는 코드입니다.

* 2 calculate\_angle.py : 랜드마크 데이터(CSV)를 기반으로 고관절 각도를 계산하는 핵심 로직입니다.

* 3 video\_and\_graph\_visualizer.py : 계산된 각도 데이터를 영상과 함께 동기화하여 시각화하는 코드입니다.

* processed\_data/ : 분석에 사용된 샘플 CSV 데이터 파일이 포함되어 있습니다.



## 🎬 시연 영상 (Demonstration)


https://youtu.be/My92in6GzkM
https://youtu.be/-gsdTwBnxOk
https://youtu.be/Iv4sl9wL-TQ
https://youtu.be/msv6gcY5ThU



## 🚀 프로젝트 실행 방법 (How to Run)


이 프로젝트를 로컬 환경에서 실행하려면 아래 단계를 따라주세요.

### 1. 저장소 클론 (Clone the repository)
터미널에서 다음 명령어를 입력하여 프로젝트 파일을 다운로드합니다.
```bash
git clone [https://github.com/Kyungmin-Hwang-hub/ballet-motion-analysis.git](https://github.com/Kyungmin-Hwang-hub/ballet-motion-analysis.git)
cd ballet-motion-analysis
'''

### 2. 환경 설정 및 라이브러리 설치 (Setup Environment & Install dependencies)

# (선택 사항) 가상 환경 생성 및 활성화
python -m venv venv
source venv/bin/activate # macOS/Linux
# venv\Scripts\activate # Windows

# requirements.txt 파일에 명시된 라이브러리 설치
pip install -r requirements.txt

# 1단계: 영상에서 랜드마크 데이터 추출
python 1_extract_data.py

# 2단계: 추출된 데이터를 기반으로 각도 계산
python 2_calculate_angle.py

# 3단계: 최종 시각화 결과 확인
python 3_video_and_graph_visualizer.py





## 🔬 분석 결과 및 인사이트 (Analysis Results & Insights)


본 프로젝트는 딥러닝에 기반하여 동작을 추적하는 mediapipe를 활용하여 고관절의 다양한 움직임을 정량화했습니다. 이를 통해 인체 동작의 미묘한 차이를 밝혀내고, 데이터 기반으로 불균형과 보상 작용을 분석하는 데 중점을 두었습니다.

---

## 1. Hip Abduction (고관절 외전) 분석

### 측정값
- **오른쪽**: `131.49 - 90 = 41.49도`
- **왼쪽**: `160.17 - 90 = 70.17도`

> *측정 방식: 고관절 외전 각도는 두 벡터가 이루는 각도를 계산하여 측정했습니다.
> - 첫 번째 벡터(기준 벡터): 몸통의 중심선(Mid-Hip Landmark 기준 수직축)
> - 두 번째 벡터(움직임 벡터): 고관절 랜드마크에서 무릎 랜드마크로 이어지는 선
> 초기 자세(두 발 딛고 바로 선 자세)의 각도를 `90도`로 설정하고, 이 기준 각도와의 차이를 실제 외전 각도로 정의했습니다.


### 해석
- **현저한 좌우 비대칭(Asymmetry)**: 왼쪽 고관절의 외전 가동 범위(ROM)가 오른쪽보다 약 **28.68도** 더 넓은 것으로 나타났습니다.
- **임상적 의미**: 이러한 큰 차이는 오른쪽 고관절 주변 근육(중둔근, 소둔근)의 약화, 관절 경직 또는 과거 부상에 의한 **가동 범위 제한**을 시사합니다. 이는 오른쪽 다리 외전 근육이 기능적으로 불균형할 가능성이 높다는 것을 의미합니다.

---

## 2. Hip Abduction & External Rotation 복합 움직임 분석

### 측정값
- **오른쪽**: `53.15도`
- **왼쪽**: `59.23도`

> *측정 방식: 고관절이 90도 굴곡된 상태에서, 고관절-무릎 벡터의 Z축 회전 각도를 계산하여 외전 및 외회전 각도를 근사했습니다.*

### 해석
- **지속적인 좌우 비대칭 확인**: 고관절이 90도 굴곡된 상태에서 외전 및 외회전 복합 움직임을 측정했을 때도, 여전히 왼쪽 고관절의 가동 범위가 오른쪽보다 약 **6.08도** 더 넓었습니다.
- **기능적 연관성**: 이는 단독 외전 움직임(1번)에서 나타난 비대칭이 **특정 움직임에만 국한되지 않고**, 굴곡과 외회전이 결합된 **기능적 동작에서도 일관되게 나타남**을 의미합니다. 이는 전반적인 고관절 기능에 불균형이 존재할 가능성을 높게 시사합니다.

---

## 3. Hip Abduction & Flexion & External Rotation 복합 움직임 분석

### 측정값
- **오른쪽**: `외전 135.44-90=45.44도`, `굴곡 180-11.67=168.33도`, `외전&외회전 복합 179.30도`
- **왼쪽**: `외전 131.91-90=41.91도`, `굴곡 180-14.04=165.96도`, `외전&외회전 복합 174.74도`

> *측정 방식: 고관절의 복합 움직임은 각 운동 요소(외전, 굴곡, 외회전)에 대해 개별적으로 계산했습니다.
> - 외전: 섹션 1과 동일하게 몸통과 허벅지 벡터 간의 각도를 측정했습니다.
> - 굴곡: 고관절과 어깨, 무릎 랜드마크를 활용하여 굴곡 각도를 계산했습니다.
> - 외전&외회전 복합: 섹션 2와 동일하게 고관절-무릎 벡터의 Z축 회전 각도를 근사했습니다.*

### 해석
- **복합 동작에서의 흥미로운 반전**: 단독 외전 움직임(1번)에서는 왼쪽이 더 넓은 가동 범위를 보였으나, 굴곡과 외회전이 결합된 복합 동작에서는 **오른쪽 고관절의 모든 움직임(외전, 굴곡, 외회전)이 왼쪽보다 더 넓은 가동 범위를 보였습니다.**
    - 외전: 오른쪽 `45.44도` > 왼쪽 `41.91도` (3.53도 차이)
    - 굴곡: 오른쪽 `168.33도` > 왼쪽 `165.96도` (2.37도 차이)
    - 외전&외회전 복합: 오른쪽 `179.30도` > 왼쪽 `174.74도` (4.56도 차이)
- **보상 작용(Compensatory Movement) 가능성**: 이 결과는 한 가지 동작만을 측정할 때와 달리, 여러 동작이 결합될 때 인체의 **보상 작용**이 개입했을 가능성을 보여줍니다. 즉, 오른 다리가 특정 움직임에서 기능적 제한을 보상하기 위해 다른 움직임을 활용했을 수 있습니다.
- 이러한 복합 동작 분석은 단일 동작 측정만으로는 알 수 없었던 인체의 복잡한 동작 메커니즘과 **불균형의 원인**을 추론할 수 있게 해주는 핵심적인 데이터입니다.

---

## 프로젝트의 의의와 한계

이 프로젝트는 딥러닝 기반 동작 추적 기술을 통해 인체의 움직임을 정량적으로 분석하는 새로운 방법을 제시합니다. 단순히 가동 범위를 측정하는 것을 넘어, 좌우 움직임의 비대칭성을 정확히 파악하고, 단독 동작과 복합 동작 간의 데이터 차이를 통해 보상 작용을 정량적으로 확인하고 시각화했다는 점에 의의가 있습니다. 이러한 분석은 신체 불균형의 원인을 더 깊이 이해하는 데 기여하며, 향후 맞춤형 운동 및 재활 프로그램 개발에 활용될 수 있는 기반을 마련했습니다.

**프로젝트 한계점 요약**
- 기술적 한계: 단일 2D 카메라 기반의 분석은 신체의 깊이(Z축) 정보를 정확히 파악하는 데 제약이 있습니다. 이로 인해 외회전과 같은 복잡한 3D 움직임의 각도 측정은 근사치에 가깝고, 조명 등 외부 환경 변화에 따라 달라질 수 있습니다.
- 데이터의 한계: 단 한 명의 피험자를 대상으로 한 사례 연구이므로, 이 결과는 일반적인 경향을 나타내기 어렵습니다. 또한, 측정값의 정확도를 검증할 수 있는 '골드 스탠더드' 장비(예: 3D 모션 캡처 시스템)와의 비교 과정이 포함되지 않았습니다.
- 데이터 노이즈: Mediapipe의 실시간 랜드마크 추정 오차로 인해 각도 데이터에 노이즈가 존재합니다. 향후 연구에서는 **저역 통과 필터(Low-pass filter)**나 **이동 평균 필터(Moving Average filter)**를 적용하여 데이터의 신뢰도를 높일 수 있습니다.

따라서, 향후 다양한 피험자를 대상으로 한 검증 및 더 정교한 3D 분석 기술 도입이 필요합니다.
